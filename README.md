# QSTAR 

QSTAR is a perceptual video quality model that can predict the impact of compression parameters on video.  We have proved the validity of the model in many scenarios, including plane video, viewport video and omnidirectional video. 

## QSTAR for Plane Video

In the paper ["  *Q-STAR: A Perceptual Video Quality Model Considering Impact of Spatial, Temporal, and Amplitude Resolutions* "]( https://ieeexplore.ieee.org/document/6728690 ), we investigate the impact of spatial, temporal, and amplitude resolution on the perceptual quality of a compressed video. Subjective quality tests were carried out on a mobile device and a total of **189 processed video sequences** with 10 source sequences included in the test. Subjective data reveal that the impact of spatial resolution (SR), temporal resolution (TR), and quantization step-size (QS) can each be captured by a function with a single content-dependent parameter, which indicates the decay rate of the quality with each resolution factor. The joint impact of SR, TR, and QS can be accurately modeled by the product of these three functions with only three parameters. The impact of SR and QS on the quality are
independent of that of TR, but there are significant interactions between SR and QS. Furthermore, the model parameters can be predicted accurately from a few content features derived from the original video. The proposed model correlates well with the subjective ratings with a **Pearson correlation coefficient of 0.985** when the model parameters are predicted from content features. The quality model is further validated on six other subjective rating data sets with very high accuracy and outperforms several well-known quality models.

### Related Papers

- Yao Wang, Zhan Ma and Yen-Fu Ou, "[*Modeling rate and perceptual quality of scalable video as functions of quantization and frame rate and its application in scalable video adaptation,*]( https://ieeexplore.ieee.org/document/5152161 )" *2009 17th International Packet Video Workshop*, Seattle, WA, 2009, pp. 1-9, doi: 10.1109/PACKET.2009.5152161. 
- Y. Ou, Z. Ma, T. Liu and Y. Wang, "[*Perceptual Quality Assessment of Video Considering Both Frame Rate and Quantization Artifacts*]( https://ieeexplore.ieee.org/document/5604671 )," in *IEEE Transactions on Circuits and Systems for Video Technology*, vol. 21, no. 3, pp. 286-298, March 2011, doi: 10.1109/TCSVT.2010.2087833. 
- Y. Ou, Y. Xue, Z. Ma and Y. Wang, "[*A perceptual video quality model for mobile platform considering impact of spatial, temporal, and amplitude resolutions*]( https://ieeexplore.ieee.org/document/5970365 )," *2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis*, Ithaca, NY, 2011, pp. 117-122, doi: 10.1109/IVMSPW.2011.5970365. 
- Y. Ou, Y. Xue and Y. Wang, "[*Q-STAR: A Perceptual Video Quality Model Considering Impact of Spatial, Temporal, and Amplitude Resolutions*]( https://ieeexplore.ieee.org/document/6728690 )," in IEEE Transactions on Image Processing, vol. 23, no. 6, pp. 2473-2486, June 2014, doi: 10.1109/TIP.2014.2303636.

## QSTAR for Immersive Viewing

We have witnessed the exponential growth of the video  applications. Particularly, panoramic and omnidirectional videos and images (ODV or ODI) are becoming increasingly popular. Therefore, we have extended the QSTAR model to immersive viewing, including a viewport video subjective quality assessment database, a quality model for viewport video and a quality for ODV. 

### Database

We first provides a new Viewport-based Omnidirectional Video Quality Assessment (VOD-VQA) database, which includes eighteen raw viewport videos  covering the salient regions of omnidirectional video (ODV) contents, and corresponding 774 impaired samples generated by compressing the raw content using a variety of combinations of its Spatial (frame size, s), Temporal (frame rate, t), and Amplitude (quantization step-size, q) Resolutions (STAR). Total 160 subjects have participated to assess the processed viewport videos rendered on the head mounted display (HMD) when they stabilize their fixations to the salient areas. 

#### Download:

[MOS data]( http://yun.nju.edu.cn/f/afc0dbce1b/ )

[Test Viewport videos]( http://yun.nju.edu.cn/f/354aa9169e/ )

[Validation Viewport videos](  http://yun.nju.edu.cn/f/f393696b3d/ )

[Demo Video and Saliency Map in Main Function]( http://yun.nju.edu.cn/f/012f2bd3f3/ )

### Model

#### Quality Model for Viewport Video

We have developed an analytical model to connect the perceptual quality of a compressed viewport video with its STAR variables. All four model parameters can be linearly predicted using extracted content features, making the proposed metric generalized to various contents.  This model correlates well with the mean opinion scores (MOSs) of viewport videos. 

#### Quality Model for ODV

The viewport-based quality model can be easily extended to infer the overall ODV quality by linearly weighing the saliency-aggregated qualities of salient viewports and the quality of quick-scanning (or non-salient) area. Experiments have shown that inferred model correlates with the collected MOS very well with competitive performance to the state-of-the-art algorithm, across another four independent and third-party ODV assessment datasets, including [IPP_IVQD]( https://ieeexplore.ieee.org/document/8350375 ), [IVQAD2017]( https://ieeexplore.ieee.org/document/7965610 ), [ISTOmnidirectional]( https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10752/107520P/Subjective-and-objective-quality-assessment-of-omnidirectional-video/10.1117/12.2321679.short?SSO=1 ) and [VQA-ODV]( https://github.com/Archer-Tatsu/VQA-ODV ).

### Related Scripts

We have uploaded the relevant scripts for the model calculation. The main function is ``QSTAR_ODV_com.m``.

###  **Notes**

- Make sure you have FFmpeg environment variables in your system.
- We used the saliency prediction method in ["Saliency in VR: How Do People Explore Virtual Environments?"]( https://vsitzmann.github.io/vr-saliency/ ). Other methods for ODV saliency prediction are also effective, which will have an impact on the accuracy of the final result .
- The input ODV size for the above scripts is 3840x1920. The corresponding parameters in ``QSTAR_ODV_com.m`` and ``viewport_extract.m``.